# MediAssist-Pro - Guide des T√¢ches

## üìã PHASE 1 : CONFIGURATION INITIALE DU PROJET

### T√¢che 1.1 : Structure des dossiers
**Objectif** : Cr√©er l'architecture compl√®te du projet

Cr√©er la structure suivante :
```
MediAssist-Pro/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deps.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ auth.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ users.py
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ rag.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document_processor.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chunking.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ retriever.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test_auth.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test_rag.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ test_users.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ documents/
‚îÇ   ‚îî‚îÄ‚îÄ manuals/
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

**üìù Documentation √† produire** :
- Cr√©er un fichier `docs/ARCHITECTURE.md` expliquant le r√¥le de chaque dossier
- Diagramme de l'architecture globale (dessin simple ou texte)

---

### T√¢che 1.2 : Fichier .gitignore
**Objectif** : √âviter de committer des fichiers sensibles

Cr√©er `.gitignore` avec :
```
__pycache__/
*.py[cod]
*$py.class
.env
*.db
*.sqlite
.venv/
venv/
env/
.idea/
.vscode/
*.log
.pytest_cache/
.coverage
htmlcov/
dist/
build/
*.egg-info/
chroma_db/
faiss_index/
```

**üìù Documentation √† produire** :
- Aucune documentation sp√©cifique

---

### T√¢che 1.3 : Fichier requirements.txt
**Objectif** : Lister toutes les d√©pendances Python

Cr√©er `backend/requirements.txt` :
```
fastapi==0.109.0
uvicorn[standard]==0.27.0
sqlalchemy==2.0.25
psycopg2-binary==2.9.9
alembic==1.13.1
pydantic==2.5.3
pydantic-settings==2.1.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.6
langchain==0.1.0
langchain-community==0.0.13
langchain-openai==0.0.5
chromadb==0.4.22
sentence-transformers==2.3.1
pypdf==3.17.4
pytest==7.4.3
pytest-asyncio==0.23.3
httpx==0.26.0
python-dotenv==1.0.0
```

**üìù Documentation √† produire** :
- Dans `docs/DEPENDENCIES.md` : expliquer le r√¥le de chaque biblioth√®que principale

---

### T√¢che 1.4 : Variables d'environnement
**Objectif** : Configurer les param√®tres sensibles

Cr√©er `backend/.env.example` :
```
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/mediassist_db

# JWT
SECRET_KEY=your-secret-key-here-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# OpenAI or LLM API
OPENAI_API_KEY=your-openai-api-key-here
# or for local models
OLLAMA_BASE_URL=http://localhost:11434

# Embeddings
EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Vector Store
VECTOR_STORE_TYPE=chromadb
CHROMA_PERSIST_DIRECTORY=./chroma_db

# App
APP_NAME=MediAssist-Pro
DEBUG=True
```

**üìù Documentation √† produire** :
- Dans `docs/CONFIGURATION.md` : expliquer chaque variable et comment les obtenir

---

## üìã PHASE 2 : BASE DE DONN√âES ET MOD√àLES

### T√¢che 2.1 : Configuration de la base de donn√©es
**Objectif** : Connecter l'application √† PostgreSQL

Cr√©er `backend/app/config.py` :
```python
from pydantic_settings import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    DATABASE_URL: str
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    OPENAI_API_KEY: Optional[str] = None
    EMBEDDINGS_MODEL: str
    VECTOR_STORE_TYPE: str = "chromadb"
    CHROMA_PERSIST_DIRECTORY: str = "./chroma_db"
    APP_NAME: str = "MediAssist-Pro"
    DEBUG: bool = False

    class Config:
        env_file = ".env"

settings = Settings()
```

Cr√©er `backend/app/database.py` :
```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from app.config import settings

engine = create_engine(settings.DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

**üìù Documentation √† produire** :
- Dans `docs/DATABASE.md` : expliquer la connexion, les sessions, et comment utiliser `get_db()`

---

### T√¢che 2.2 : Mod√®le User
**Objectif** : Cr√©er la table users

Cr√©er `backend/app/models/user.py` :
```python
from sqlalchemy import Column, Integer, String, Enum
from app.database import Base
import enum

class UserRole(str, enum.Enum):
    ADMIN = "admin"
    TECHNICIAN = "technician"
    USER = "user"

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    username = Column(String, unique=True, index=True, nullable=False)
    email = Column(String, unique=True, index=True, nullable=False)
    hashed_password = Column(String, nullable=False)
    role = Column(Enum(UserRole), default=UserRole.USER, nullable=False)
```

Cr√©er `backend/app/models/__init__.py` :
```python
from app.models.user import User
from app.models.query import Query
```

**üìù Documentation √† produire** :
- Dans `docs/DATABASE.md` : ajouter le sch√©ma de la table users avec explication des champs

---

### T√¢che 2.3 : Mod√®le Query
**Objectif** : Cr√©er la table pour historique des requ√™tes

Cr√©er `backend/app/models/query.py` :
```python
from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey
from sqlalchemy.sql import func
from app.database import Base

class Query(Base):
    __tablename__ = "queries"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    query = Column(Text, nullable=False)
    response = Column(Text, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
```

**üìù Documentation √† produire** :
- Dans `docs/DATABASE.md` : ajouter le sch√©ma de la table queries avec explication des champs

---

### T√¢che 2.4 : Sch√©mas Pydantic pour User
**Objectif** : Validation des donn√©es entrantes/sortantes

Cr√©er `backend/app/schemas/user.py` :
```python
from pydantic import BaseModel, EmailStr
from app.models.user import UserRole

class UserBase(BaseModel):
    username: str
    email: EmailStr

class UserCreate(UserBase):
    password: str

class UserLogin(BaseModel):
    username: str
    password: str

class UserResponse(UserBase):
    id: int
    role: UserRole

    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    username: str | None = None
```

**üìù Documentation √† produire** :
- Dans `docs/API_SCHEMAS.md` : expliquer chaque sch√©ma et son usage (cr√©ation, login, r√©ponse)

---

### T√¢che 2.5 : Sch√©mas Pydantic pour Query
**Objectif** : Validation des requ√™tes RAG

Cr√©er `backend/app/schemas/query.py` :
```python
from pydantic import BaseModel
from datetime import datetime

class QueryCreate(BaseModel):
    query: str

class QueryResponse(BaseModel):
    id: int
    query: str
    response: str
    created_at: datetime

    class Config:
        from_attributes = True

class RAGRequest(BaseModel):
    question: str
    top_k: int = 5

class RAGResponse(BaseModel):
    answer: str
    sources: list[str]
    query_id: int
```

**üìù Documentation √† produire** :
- Dans `docs/API_SCHEMAS.md` : ajouter les sch√©mas RAG avec exemples JSON

---

## üìã PHASE 3 : AUTHENTIFICATION ET S√âCURIT√â

### T√¢che 3.1 : Module de s√©curit√©
**Objectif** : Impl√©menter JWT et hash de mots de passe

Cr√©er `backend/app/core/security.py` :
```python
from datetime import datetime, timedelta
from jose import JWTError, jwt
from passlib.context import CryptContext
from app.config import settings

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    return pwd_context.hash(password)

def create_access_token(data: dict, expires_delta: timedelta | None = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

def decode_token(token: str):
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        return payload
    except JWTError:
        return None
```

**üìù Documentation √† produire** :
- Dans `docs/SECURITY.md` : expliquer JWT, bcrypt, et le flux d'authentification

---

### T√¢che 3.2 : Gestion des exceptions
**Objectif** : Centraliser les erreurs HTTP

Cr√©er `backend/app/core/exceptions.py` :
```python
from fastapi import HTTPException, status

class CredentialsException(HTTPException):
    def __init__(self):
        super().__init__(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

class UserNotFoundException(HTTPException):
    def __init__(self):
        super().__init__(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="User not found"
        )

class UserAlreadyExistsException(HTTPException):
    def __init__(self):
        super().__init__(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="User already exists"
        )

class DocumentProcessingException(HTTPException):
    def __init__(self, detail: str = "Error processing document"):
        super().__init__(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=detail
        )
```

**üìù Documentation √† produire** :
- Dans `docs/ERROR_HANDLING.md` : lister toutes les exceptions et leurs codes HTTP

---

### T√¢che 3.3 : D√©pendances d'authentification
**Objectif** : Cr√©er les d√©pendances pour prot√©ger les routes

Cr√©er `backend/app/api/deps.py` :
```python
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session
from app.database import get_db
from app.core.security import decode_token
from app.models.user import User
from app.core.exceptions import CredentialsException

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="api/auth/login")

def get_current_user(
    token: str = Depends(oauth2_scheme),
    db: Session = Depends(get_db)
) -> User:
    payload = decode_token(token)
    if payload is None:
        raise CredentialsException()
    
    username: str = payload.get("sub")
    if username is None:
        raise CredentialsException()
    
    user = db.query(User).filter(User.username == username).first()
    if user is None:
        raise CredentialsException()
    
    return user

def get_current_admin_user(
    current_user: User = Depends(get_current_user)
) -> User:
    if current_user.role != "admin":
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Not enough permissions"
        )
    return current_user
```

**üìù Documentation √† produire** :
- Dans `docs/AUTHENTICATION.md` : expliquer le flux OAuth2, comment prot√©ger une route

---

### T√¢che 3.4 : Routes d'authentification
**Objectif** : Cr√©er login et register

Cr√©er `backend/app/api/routes/auth.py` :
```python
from fastapi import APIRouter, Depends, HTTPException, status
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.orm import Session
from datetime import timedelta
from app.database import get_db
from app.schemas.user import UserCreate, UserResponse, Token
from app.models.user import User
from app.core.security import verify_password, get_password_hash, create_access_token
from app.core.exceptions import UserAlreadyExistsException
from app.config import settings

router = APIRouter(prefix="/auth", tags=["Authentication"])

@router.post("/register", response_model=UserResponse, status_code=status.HTTP_201_CREATED)
def register(user: UserCreate, db: Session = Depends(get_db)):
    # Check if user exists
    db_user = db.query(User).filter(User.username == user.username).first()
    if db_user:
        raise UserAlreadyExistsException()
    
    # Create new user
    hashed_password = get_password_hash(user.password)
    new_user = User(
        username=user.username,
        email=user.email,
        hashed_password=hashed_password
    )
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    return new_user

@router.post("/login", response_model=Token)
def login(
    form_data: OAuth2PasswordRequestForm = Depends(),
    db: Session = Depends(get_db)
):
    user = db.query(User).filter(User.username == form_data.username).first()
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password"
        )
    
    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.username}, expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer"}
```

**üìù Documentation √† produire** :
- Dans `docs/API_ENDPOINTS.md` : documenter POST /auth/register et POST /auth/login avec exemples curl

---

## üìã PHASE 4 : PIPELINE RAG - PR√âTRAITEMENT

### T√¢che 4.1 : Processeur de documents
**Objectif** : Charger les PDF

Cr√©er `backend/app/rag/document_processor.py` :
```python
from pathlib import Path
from typing import List
from pypdf import PdfReader
from langchain.docstore.document import Document

class DocumentProcessor:
    """Charge et extrait le texte des documents PDF."""
    
    def __init__(self, documents_dir: str = "./documents/manuals"):
        self.documents_dir = Path(documents_dir)
    
    def load_pdf(self, file_path: str) -> List[Document]:
        """Charge un fichier PDF et retourne une liste de Documents."""
        reader = PdfReader(file_path)
        documents = []
        
        for page_num, page in enumerate(reader.pages):
            text = page.extract_text()
            metadata = {
                "source": str(file_path),
                "page": page_num + 1,
                "total_pages": len(reader.pages)
            }
            documents.append(Document(page_content=text, metadata=metadata))
        
        return documents
    
    def load_all_pdfs(self) -> List[Document]:
        """Charge tous les PDFs du r√©pertoire."""
        all_documents = []
        pdf_files = list(self.documents_dir.glob("*.pdf"))
        
        for pdf_file in pdf_files:
            docs = self.load_pdf(str(pdf_file))
            all_documents.extend(docs)
        
        return all_documents
```

**üìù Documentation √† produire** :
- Dans `docs/RAG_PIPELINE.md` : expliquer le chargement des PDF et la structure Document

---

### T√¢che 4.2 : Chunking des documents
**Objectif** : D√©couper intelligemment les documents

Cr√©er `backend/app/rag/chunking.py` :
```python
from typing import List
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document

class DocumentChunker:
    """D√©coupe les documents en chunks avec overlap."""
    
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", " ", ""]
        )
    
    def chunk_documents(self, documents: List[Document]) -> List[Document]:
        """D√©coupe une liste de documents en chunks."""
        chunks = self.text_splitter.split_documents(documents)
        
        # Enrichir les m√©tadonn√©es avec l'ID du chunk
        for i, chunk in enumerate(chunks):
            chunk.metadata["chunk_id"] = i
            chunk.metadata["chunk_size"] = len(chunk.page_content)
        
        return chunks
```

**üìù Documentation √† produire** :
- Dans `docs/RAG_PIPELINE.md` : expliquer la strat√©gie de chunking, chunk_size, overlap et pourquoi

---

### T√¢che 4.3 : G√©n√©ration des embeddings
**Objectif** : Transformer les chunks en vecteurs

Cr√©er `backend/app/rag/embeddings.py` :
```python
from langchain_community.embeddings import HuggingFaceEmbeddings
from app.config import settings

class EmbeddingsManager:
    """G√®re la g√©n√©ration des embeddings."""
    
    def __init__(self):
        self.embeddings_model = HuggingFaceEmbeddings(
            model_name=settings.EMBEDDINGS_MODEL,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
    
    def get_embeddings(self):
        """Retourne le mod√®le d'embeddings."""
        return self.embeddings_model
```

**üìù Documentation √† produire** :
- Dans `docs/RAG_PIPELINE.md` : expliquer ce qu'est un embedding, le mod√®le choisi et pourquoi

---

## üìã PHASE 5 : VECTOR STORE ET RETRIEVAL

### T√¢che 5.1 : Vector Store (ChromaDB)
**Objectif** : Stocker et persister les embeddings

Cr√©er `backend/app/rag/vector_store.py` :
```python
from typing import List
from langchain_community.vectorstores import Chroma
from langchain.docstore.document import Document
from app.rag.embeddings import EmbeddingsManager
from app.config import settings

class VectorStoreManager:
    """G√®re le vector store ChromaDB."""
    
    def __init__(self):
        self.embeddings_manager = EmbeddingsManager()
        self.embeddings = self.embeddings_manager.get_embeddings()
        self.persist_directory = settings.CHROMA_PERSIST_DIRECTORY
    
    def create_vector_store(self, documents: List[Document]) -> Chroma:
        """Cr√©e un nouveau vector store √† partir de documents."""
        vector_store = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory=self.persist_directory
        )
        return vector_store
    
    def load_vector_store(self) -> Chroma:
        """Charge un vector store existant."""
        vector_store = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embeddings
        )
        return vector_store
    
    def add_documents(self, documents: List[Document]):
        """Ajoute des documents √† un vector store existant."""
        vector_store = self.load_vector_store()
        vector_store.add_documents(documents)
```

**üìù Documentation √† produire** :
- Dans `docs/VECTOR_STORE.md` : expliquer ChromaDB, la persistance, comment ajouter des docs

---

### T√¢che 5.2 : Retriever avanc√©
**Objectif** : Rechercher les chunks pertinents

Cr√©er `backend/app/rag/retriever.py` :
```python
from typing import List
from langchain.docstore.document import Document
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from app.rag.vector_store import VectorStoreManager

class RetrieverManager:
    """G√®re la r√©cup√©ration des documents pertinents."""
    
    def __init__(self, top_k: int = 5):
        self.vector_store_manager = VectorStoreManager()
        self.vector_store = self.vector_store_manager.load_vector_store()
        self.top_k = top_k
    
    def search(self, query: str) -> List[Document]:
        """Recherche les documents les plus pertinents."""
        retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": self.top_k}
        )
        documents = retriever.get_relevant_documents(query)
        return documents
    
    def search_with_score(self, query: str) -> List[tuple]:
        """Recherche avec scores de similarit√©."""
        results = self.vector_store.similarity_search_with_score(query, k=self.top_k)
        return results
```

**üìù Documentation √† produire** :
- Dans `docs/RETRIEVAL.md` : expliquer la recherche par similarit√©, le param√®tre top_k

---

## üìã PHASE 6 : G√âN√âRATION DE R√âPONSE

### T√¢che 6.1 : G√©n√©rateur de r√©ponses
**Objectif** : Utiliser un LLM pour g√©n√©rer des r√©ponses

Cr√©er `backend/app/rag/generator.py` :
```python
from typing import List
from langchain.docstore.document import Document
from langchain.chains import RetrievalQA
from langchain_community.llms import Ollama
from langchain.prompts import PromptTemplate
from app.rag.retriever import RetrieverManager
from app.config import settings

class ResponseGenerator:
    """G√©n√®re des r√©ponses en utilisant RAG."""
    
    def __init__(self):
        self.retriever_manager = RetrieverManager()
        
        # Prompt template
        self.prompt_template = """Tu es un assistant technique sp√©cialis√© dans les √©quipements biom√©dicaux de laboratoire.
        
Utilise UNIQUEMENT les informations du contexte suivant pour r√©pondre √† la question.
Si la r√©ponse n'est pas dans le contexte, dis "Je ne trouve pas cette information dans les manuels techniques disponibles."

Contexte:
{context}

Question: {question}

Instructions:
- R√©ponds de mani√®re pr√©cise et actionnable
- Cite la source (nom du fichier et page) si possible
- Utilise un langage technique mais compr√©hensible
- Structure ta r√©ponse avec des points si n√©cessaire

R√©ponse:"""

        self.prompt = PromptTemplate(
            template=self.prompt_template,
            input_variables=["context", "question"]
        )
    
    def generate_answer(self, question: str, top_k: int = 5) -> dict:
        """G√©n√®re une r√©ponse √† partir de la question."""
        # R√©cup√©rer les documents pertinents
        self.retriever_manager.top_k = top_k
        documents = self.retriever_manager.search(question)
        
        # Construire le contexte
        context = "\n\n".join([
            f"[Source: {doc.metadata.get('source', 'Unknown')} - Page {doc.metadata.get('page', 'N/A')}]\n{doc.page_content}"
            for doc in documents
        ])
        
        # G√©n√©rer la r√©ponse (vous pouvez utiliser OpenAI ou Ollama)
        # Pour l'exemple avec Ollama:
        llm = Ollama(model="llama2", base_url=settings.OLLAMA_BASE_URL)
        
        full_prompt = self.prompt.format(context=context, question=question)
        answer = llm(full_prompt)
        
        # Extraire les sources
        sources = [
            f"{doc.metadata.get('source', 'Unknown')} (Page {doc.metadata.get('page', 'N/A')})"
            for doc in documents
        ]
        
        return {
            "answer": answer,
            "sources": sources,
            "retrieved_chunks": len(documents)
        }
```

**üìù Documentation √† produire** :
- Dans `docs/GENERATION.md` : expliquer le prompt engineering, le choix du LLM, la structure de r√©ponse

---

## üìã PHASE 7 : ROUTES API RAG

### T√¢che 7.1 : Route pour indexer des documents
**Objectif** : API pour charger et indexer des PDFs

Cr√©er `backend/app/api/routes/rag.py` :
```python
from fastapi import APIRouter, Depends, UploadFile, File, HTTPException
from sqlalchemy.orm import Session
from app.database import get_db
from app.api.deps import get_current_user
from app.models.user import User
from app.models.query import Query
from app.schemas.query import RAGRequest, RAGResponse
from app.rag.document_processor import DocumentProcessor
from app.rag.chunking import DocumentChunker
from app.rag.vector_store import VectorStoreManager
from app.rag.generator import ResponseGenerator
import shutil
from pathlib import Path

router = APIRouter(prefix="/rag", tags=["RAG"])

@router.post("/index")
async def index_documents(
    current_user: User = Depends(get_current_user)
):
    """Indexe tous les documents PDF du dossier documents/manuals."""
    try:
        # Charger les documents
        processor = DocumentProcessor()
        documents = processor.load_all_pdfs()
        
        if not documents:
            raise HTTPException(status_code=404, detail="No PDF documents found")
        
        # Chunker les documents
        chunker = DocumentChunker()
        chunks = chunker.chunk_documents(documents)
        
        # Cr√©er le vector store
        vector_store_manager = VectorStoreManager()
        vector_store_manager.create_vector_store(chunks)
        
        return {
            "message": "Documents indexed successfully",
            "total_documents": len(documents),
            "total_chunks": len(chunks)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error indexing documents: {str(e)}")

@router.post("/upload")
async def upload_document(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user)
):
    """Upload un nouveau document PDF."""
    if not file.filename.endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Only PDF files are allowed")
    
    try:
        documents_dir = Path("./documents/manuals")
        documents_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = documents_dir / file.filename
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        return {"message": f"File {file.filename} uploaded successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error uploading file: {str(e)}")

@router.post("/query", response_model=RAGResponse)
async def query_rag(
    request: RAGRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Interroge le syst√®me RAG."""
    try:
        # G√©n√©rer la r√©ponse
        generator = ResponseGenerator()
        result = generator.generate_answer(request.question, top_k=request.top_k)
        
        # Sauvegarder dans la base de donn√©es
        new_query = Query(
            user_id=current_user.id,
            query=request.question,
            response=result["answer"]
        )
        db.add(new_query)
        db.commit()
        db.refresh(new_query)
        
        return RAGResponse(
            answer=result["answer"],
            sources=result["sources"],
            query_id=new_query.id
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing query: {str(e)}")

@router.get("/history")
async def get_query_history(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    limit: int = 10
):
    """R√©cup√®re l'historique des requ√™tes de l'utilisateur."""
    queries = db.query(Query).filter(
        Query.user_id == current_user.id
    ).order_by(Query.created_at.desc()).limit(limit).all()
    
    return queries
```

**üìù Documentation √† produire** :
- Dans `docs/API_ENDPOINTS.md` : documenter POST /rag/index, POST /rag/upload, POST /rag/query avec exemples

---

## üìã PHASE 8 : APPLICATION PRINCIPALE

### T√¢che 8.1 : Fichier main.py
**Objectif** : Assembler toute l'application FastAPI

Cr√©er `backend/app/main.py` :
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.config import settings
from app.database import engine, Base
from app.api.routes import auth, rag

# Cr√©er les tables
Base.metadata.create_all(bind=engine)

app = FastAPI(
    title=settings.APP_NAME,
    description="RAG system for biomedical equipment technical manuals",
    version="1.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(auth.router, prefix="/api")
app.include_router(rag.router, prefix="/api")

@app.get("/")
async def root():
    return {
        "message": "Welcome to MediAssist-Pro API",
        "docs": "/docs"
    }

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

**üìù Documentation √† produire** :
- Dans `docs/API_OVERVIEW.md` : vue d'ensemble de l'API, comment d√©marrer, routes disponibles

---

## üìã PHASE 9 : DOCKER ET D√âPLOIEMENT

### T√¢che 9.1 : Dockerfile pour le backend
**Objectif** : Conteneuriser l'application

Cr√©er `backend/Dockerfile` :
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 8000

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

**üìù Documentation √† produire** :
- Dans `docs/DOCKER.md` : expliquer le Dockerfile ligne par ligne

---

### T√¢che 9.2 : Docker Compose
**Objectif** : Orchestrer backend + PostgreSQL

Cr√©er `docker-compose.yml` :
```yaml
version: '3.8'

services:
  db:
    image: postgres:15
    container_name: mediassist_db
    environment:
      POSTGRES_USER: mediassist_user
      POSTGRES_PASSWORD: mediassist_password
      POSTGRES_DB: mediassist_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mediassist_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: mediassist_backend
    depends_on:
      db:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql://mediassist_user:mediassist_password@db:5432/mediassist_db
      SECRET_KEY: your-secret-key-change-in-production
      ALGORITHM: HS256
      ACCESS_TOKEN_EXPIRE_MINUTES: 30
      EMBEDDINGS_MODEL: sentence-transformers/all-MiniLM-L6-v2
      VECTOR_STORE_TYPE: chromadb
      CHROMA_PERSIST_DIRECTORY: /app/chroma_db
      OLLAMA_BASE_URL: http://host.docker.internal:11434
    volumes:
      - ./backend:/app
      - ./documents:/app/documents
      - chroma_data:/app/chroma_db
    ports:
      - "8000:8000"

volumes:
  postgres_data:
  chroma_data:
```

**üìù Documentation √† produire** :
- Dans `docs/DOCKER.md` : expliquer docker-compose, les volumes, comment d√©marrer

---

## üìã PHASE 10 : TESTS

### T√¢che 10.1 : Tests d'authentification
**Objectif** : Tester le syst√®me d'auth

Cr√©er `backend/app/tests/test_auth.py` :
```python
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_register_user():
    response = client.post(
        "/api/auth/register",
        json={
            "username": "testuser",
            "email": "test@example.com",
            "password": "testpassword123"
        }
    )
    assert response.status_code == 201
    data = response.json()
    assert data["username"] == "testuser"
    assert data["email"] == "test@example.com"

def test_login_user():
    response = client.post(
        "/api/auth/login",
        data={
            "username": "testuser",
            "password": "testpassword123"
        }
    )
    assert response.status_code == 200
    data = response.json()
    assert "access_token" in data
    assert data["token_type"] == "bearer"

def test_login_invalid_credentials():
    response = client.post(
        "/api/auth/login",
        data={
            "username": "testuser",
            "password": "wrongpassword"
        }
    )
    assert response.status_code == 401
```

**üìù Documentation √† produire** :
- Dans `docs/TESTING.md` : expliquer comment ex√©cuter les tests, pytest, coverage

---

### T√¢che 10.2 : Tests RAG
**Objectif** : Tester le pipeline RAG

Cr√©er `backend/app/tests/test_rag.py` :
```python
import pytest
from app.rag.document_processor import DocumentProcessor
from app.rag.chunking import DocumentChunker
from app.rag.embeddings import EmbeddingsManager

def test_document_processor():
    processor = DocumentProcessor()
    # Tester avec un PDF de test
    # documents = processor.load_pdf("test.pdf")
    # assert len(documents) > 0

def test_chunking():
    chunker = DocumentChunker(chunk_size=500, chunk_overlap=50)
    # Test chunking logic
    pass

def test_embeddings():
    embeddings_manager = EmbeddingsManager()
    embeddings = embeddings_manager.get_embeddings()
    assert embeddings is not None
```

**üìù Documentation √† produire** :
- Dans `docs/TESTING.md` : ajouter les tests RAG et comment les ex√©cuter

---

## üìã PHASE 11 : README ET DOCUMENTATION FINALE

### T√¢che 11.1 : README principal
**Objectif** : Guide complet du projet

Mettre √† jour `README.md` :
```markdown
# MediAssist-Pro

Syst√®me RAG (Retrieval-Augmented Generation) pour l'assistance technique sur √©quipements biom√©dicaux.

## üöÄ Fonctionnalit√©s

- üîê Authentification JWT
- üìÑ Indexation de manuels techniques (PDF)
- ü§ñ R√©ponses intelligentes via RAG
- üìä Historique des requ√™tes
- üîç Recherche vectorielle avec ChromaDB
- üê≥ D√©ploiement avec Docker

## üõ†Ô∏è Technologies

- FastAPI
- PostgreSQL
- LangChain
- ChromaDB
- Sentence Transformers
- Docker

## üì¶ Installation

### Avec Docker (Recommand√©)

1. Cloner le repo
2. Copier `.env.example` vers `.env`
3. Lancer : `docker-compose up -d`
4. Acc√©der √† : http://localhost:8000/docs

### Sans Docker

1. Installer PostgreSQL
2. Cr√©er un environnement virtuel : `python -m venv venv`
3. Activer : `venv\Scripts\activate`
4. Installer : `pip install -r backend/requirements.txt`
5. Configurer `.env`
6. Lancer : `uvicorn app.main:app --reload`

## üìö Documentation

- [Architecture](docs/ARCHITECTURE.md)
- [API Endpoints](docs/API_ENDPOINTS.md)
- [RAG Pipeline](docs/RAG_PIPELINE.md)
- [Configuration](docs/CONFIGURATION.md)
- [Tests](docs/TESTING.md)

## üß™ Tests

```bash
cd backend
pytest
```

## üìñ Utilisation

1. **S'inscrire** : POST `/api/auth/register`
2. **Se connecter** : POST `/api/auth/login`
3. **Uploader un PDF** : POST `/api/rag/upload`
4. **Indexer** : POST `/api/rag/index`
5. **Poser une question** : POST `/api/rag/query`

## ü§ù Contribution

Voir [CONTRIBUTING.md](CONTRIBUTING.md)

## üìÑ Licence

MIT
```

**üìù Documentation √† produire** :
- Le README lui-m√™me est la documentation

---

### T√¢che 11.2 : Documentation compl√®te
**Objectif** : Finaliser tous les documents

S'assurer que tous ces fichiers existent dans `docs/` :

1. `ARCHITECTURE.md` - Architecture du syst√®me
2. `API_ENDPOINTS.md` - Toutes les routes API
3. `API_SCHEMAS.md` - Sch√©mas Pydantic
4. `AUTHENTICATION.md` - Syst√®me d'auth
5. `CONFIGURATION.md` - Variables d'environnement
6. `DATABASE.md` - Sch√©mas de tables
7. `DEPENDENCIES.md` - Biblioth√®ques utilis√©es
8. `DOCKER.md` - Docker et d√©ploiement
9. `ERROR_HANDLING.md` - Gestion des erreurs
10. `GENERATION.md` - G√©n√©ration de r√©ponses
11. `RAG_PIPELINE.md` - Pipeline RAG complet
12. `RETRIEVAL.md` - Syst√®me de retrieval
13. `SECURITY.md` - S√©curit√© JWT/bcrypt
14. `TESTING.md` - Tests unitaires
15. `VECTOR_STORE.md` - ChromaDB

**üìù Documentation √† produire** :
- Chaque fichier doit √™tre complet et bien structur√©

---

## üìã PHASE 12 : OPTIMISATIONS ET AM√âLIORATIONS

### T√¢che 12.1 : Query Expansion
**Objectif** : Am√©liorer la recherche en reformulant la requ√™te

Ajouter dans `backend/app/rag/retriever.py` :
```python
def expand_query(self, query: str) -> List[str]:
    """G√©n√®re des variantes de la requ√™te."""
    # Impl√©mentation simple : synonymes, reformulations
    expanded_queries = [query]
    # Ajouter logique d'expansion ici
    return expanded_queries
```

**üìù Documentation √† produire** :
- Dans `docs/ADVANCED_RAG.md` : expliquer query expansion et son impact

---

### T√¢che 12.2 : Reranking
**Objectif** : R√©ordonner les r√©sultats pour plus de pertinence

Ajouter dans `backend/app/rag/retriever.py` :
```python
from langchain.retrievers.document_compressors import CohereRerank

def rerank_results(self, query: str, documents: List[Document]) -> List[Document]:
    """R√©ordonne les documents par pertinence."""
    # Impl√©mentation de reranking
    pass
```

**üìù Documentation √† produire** :
- Dans `docs/ADVANCED_RAG.md` : expliquer le reranking

---

### T√¢che 12.3 : Cache des r√©ponses
**Objectif** : √âviter de recalculer les r√©ponses identiques

Ajouter un syst√®me de cache simple :
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_generate_answer(question: str):
    # Logique de g√©n√©ration
    pass
```

**üìù Documentation √† produire** :
- Dans `docs/PERFORMANCE.md` : expliquer le cache et ses b√©n√©fices

---

### T√¢che 12.4 : Logging
**Objectif** : Tracer toutes les op√©rations

Cr√©er `backend/app/core/logging.py` :
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger("mediassist")
```

**üìù Documentation √† produire** :
- Dans `docs/MONITORING.md` : expliquer le syst√®me de logging

---

## üìã CHECKLIST FINALE

### Avant de consid√©rer le projet termin√© :

- [ ] Toutes les tables de la base de donn√©es sont cr√©√©es
- [ ] L'authentification JWT fonctionne
- [ ] Les PDFs sont charg√©s et index√©s correctement
- [ ] Le chunking pr√©serve le contexte
- [ ] Le vector store persiste les donn√©es
- [ ] La recherche retourne des r√©sultats pertinents
- [ ] Le LLM g√©n√®re des r√©ponses coh√©rentes
- [ ] Les sources sont cit√©es dans les r√©ponses
- [ ] L'historique des requ√™tes est sauvegard√©
- [ ] Docker Compose lance tout correctement
- [ ] Les tests passent avec succ√®s
- [ ] Tous les fichiers de documentation sont complets
- [ ] Le README est clair et informatif
- [ ] Les variables d'environnement sont bien configur√©es
- [ ] La gestion des erreurs est centralis√©e

---

## üéØ R√âSUM√â DES LIVRABLES

### Code
1. Backend FastAPI complet
2. Mod√®les SQLAlchemy (User, Query)
3. Sch√©mas Pydantic
4. Routes API (Auth, RAG)
5. Pipeline RAG (chunking, embeddings, retrieval, generation)
6. Tests unitaires
7. Dockerfile + Docker Compose

### Documentation
1. README.md principal
2. 15+ fichiers de documentation technique
3. Exemples d'utilisation API
4. Guide de d√©ploiement

### Infrastructure
1. PostgreSQL configur√©
2. ChromaDB persist√©
3. Docker containerization
4. Variables d'environnement

---

## üí° CONSEILS POUR LA R√âALISATION

1. **Travailler √©tape par √©tape** : Ne passez pas √† la phase suivante avant d'avoir termin√© la pr√©c√©dente
2. **Tester r√©guli√®rement** : Apr√®s chaque t√¢che majeure, testez que tout fonctionne
3. **Commiter souvent** : Faites des commits Git apr√®s chaque t√¢che compl√©t√©e
4. **Documenter au fur et √† mesure** : Ne laissez pas la documentation pour la fin
5. **Demander de l'aide** : Si vous √™tes bloqu√©, cherchez de l'aide sur la documentation officielle

**Bon courage ! üöÄ**
